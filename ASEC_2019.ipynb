{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "#from sklearn.linear_model import LinearRegression as reg\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_true, y_pred):\n",
    "    '''\n",
    "    Calculates binary classification performance metrics for a given model.\n",
    "    :param y_true: array_like, truth values as int\n",
    "    :param y_pred: array_like, predicted values as int\n",
    "    :returns: dict, with keys for each metric: \n",
    "        accuracy - proportion of correct predictions out of total predictions\n",
    "        sensitivity - (aka recall), of all true positives reviews how many did we correctly predict as positive\n",
    "        specificity - (aka selectivity/TNR), of all true negatives how many did we correctly predict as negative\n",
    "        precision - of all predicted positive cases how many were actually positive\n",
    "        F-1 score - harmonic/weighted mean of precision and sensitivity scores\n",
    "        ROC-AUC - area under receiver operating characteristic curve\n",
    "        \n",
    "    '''\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    metrics_dict = {}\n",
    "    metrics_dict['accuracy'] = round((tp + tn) / len(y_true), 4)\n",
    "    metrics_dict['sensitivity/recall'] = round(tp / (fn + tp), 4) # aka recall\n",
    "    metrics_dict['specificity'] = round(tn / (tn + fp), 4) # aka TNR\n",
    "    metrics_dict['precision'] = round(tp / (tp + fp), 4)\n",
    "    metrics_dict['f1'] = round(2 * (metrics_dict['precision'] * metrics_dict['sensitivity/recall']) \\\n",
    "                        / (metrics_dict['precision'] + metrics_dict['sensitivity/recall']), 4)\n",
    "    metrics_dict['roc_auc'] = round(roc_auc_score(y_true, y_pred), 4)\n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prediction(X_test, pred, outcome='50k'):\n",
    "    X_test_combined = pd.concat([X_test, pd.DataFrame(y_test, columns=[outcome])], axis=1)\n",
    "    return pd.concat([X_test_combined.reset_index(drop=True), pd.DataFrame(pred, columns=['pred'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in [2019 ASEC (March CPS)](https://cps.ipums.org/cps/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/asec_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180101, 18)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YEAR  MONTH  ASECFLAG   ASECWT  RELATE  AGE  SEX  RACE  MARST  POPSTAT  \\\n",
      "0  2019      3         1  2031.67     101   21    1   100      6        1   \n",
      "1  2019      3         1  1232.04     101   85    2   100      5        1   \n",
      "2  2019      3         1  1209.17     101   61    2   100      6        1   \n",
      "3  2019      3         1  1146.23     101   73    2   100      4        1   \n",
      "4  2019      3         1  1480.79     301   37    1   100      6        1   \n",
      "\n",
      "   HISPAN  LABFORCE  UHRSWORK1  EDUC  SCHLCOLL  WKSWORK1  UHRSWORKLY  INCWAGE  \n",
      "0       0         2       30.0    60       5.0        52          30  18000.0  \n",
      "1       0         1      999.0    73       0.0         0         999      0.0  \n",
      "2       0         2       44.0    73       0.0        52          44  12000.0  \n",
      "3       0         1      999.0    73       0.0         0         999      0.0  \n",
      "4       0         2       20.0    73       5.0        52          20  12000.0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrict dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop individuals with no employment or earnings last year\n",
    "df = df.loc[df['INCWAGE'] > 0] # No wage/salary last year\n",
    "df = df.loc[(df['WKSWORK1'] > 0) & (df['WKSWORK1'] <= 52)] # No weeks worked last year\n",
    "df = df.loc[(df['UHRSWORKLY'] > 0) & (df['UHRSWORKLY'] < 999)] # No usual hours/week worked last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85644, 18)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to individuals aged 18-64\n",
    "df = df.loc[(df['AGE'] >=18) & (df['AGE'] <=64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78644, 18)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to non-Hispanics\n",
    "df = df.loc[df['HISPAN'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63125, 18)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to non-mixed-race Blacks and Whites\n",
    "df = df.loc[df.RACE.isin([100, 200])]\n",
    "df['blk'] = np.where(df['RACE'] == 200, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55508, 19)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to adult civilians\n",
    "df = df.loc[df['POPSTAT'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55069, 19)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag for part-time usual work\n",
    "df['pt'] = np.where(df['UHRSWORKLY'] < 35, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-linearities for age\n",
    "df['AGE2'] = df['AGE'] ** 2\n",
    "df['AGE3'] = df['AGE'] ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure education coded correctly\n",
    "df = df.loc[df['EDUC'] <= 125] # 999 is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly wage\n",
    "df['hrwage'] = df['INCWAGE'] / (df['WKSWORK1'] * df['UHRSWORKLY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    55069.000000\n",
       "mean        31.269112\n",
       "std        184.416973\n",
       "min          0.000962\n",
       "25%         14.375000\n",
       "50%         21.634615\n",
       "75%         34.188034\n",
       "max      25481.250000\n",
       "Name: hrwage, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hrwage'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to people earning 1 < hr_wage < 100\n",
    "df = df.loc[(df['hrwage'] > 1) & (df['hrwage'] < 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    53671.000000\n",
      "mean        25.907302\n",
      "std         17.049376\n",
      "min          1.016667\n",
      "25%         14.202864\n",
      "50%         21.634615\n",
      "75%         33.333333\n",
      "max         99.759615\n",
      "Name: hrwage, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['hrwage'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log hourly wage\n",
    "df['lnwage'] = np.log(df['hrwage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     53671.000000\n",
       "mean      52682.839876\n",
       "std       41242.872191\n",
       "min          25.000000\n",
       "25%       24617.500000\n",
       "50%       43680.000000\n",
       "75%       70000.000000\n",
       "max      420000.000000\n",
       "Name: INCWAGE, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['INCWAGE'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag for whether total earnings > 50,000 or not\n",
    "df['50k'] = np.where(df['INCWAGE'] > 50000, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['lnwage', 'hrwage', '50k', 'pt', 'INCWAGE', 'WKSWORK1', 'UHRSWORKLY', \n",
    "         'AGE', 'AGE2', 'AGE3', 'SEX', 'blk', 'MARST', 'SCHLCOLL', 'EDUC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lnwage     hrwage  50k  pt  INCWAGE  WKSWORK1  UHRSWORKLY  AGE  AGE2  \\\n",
      "0  2.445686  11.538462    0   1  18000.0        52          30   21   441   \n",
      "2  1.657229   5.244755    0   0  12000.0        52          44   61  3721   \n",
      "4  2.445686  11.538462    0   1  12000.0        52          20   37  1369   \n",
      "6  3.179655  24.038462    1   0  55000.0        52          44   53  2809   \n",
      "8  3.442059  31.251250    1   0  50002.0        40          40   62  3844   \n",
      "\n",
      "     AGE3  SEX  blk  MARST  SCHLCOLL  EDUC  \n",
      "0    9261    1    0      6       5.0    60  \n",
      "2  226981    2    0      6       0.0    73  \n",
      "4   50653    1    0      6       5.0    73  \n",
      "6  148877    2    0      4       5.0    73  \n",
      "8  238328    1    0      1       0.0   111  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['SEX', 'MARST', 'SCHLCOLL', 'EDUC', 'pt', 'blk']\n",
    "for col in categorical_features:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lnwage         float64\n",
       "hrwage         float64\n",
       "50k              int32\n",
       "pt            category\n",
       "INCWAGE        float64\n",
       "WKSWORK1         int64\n",
       "UHRSWORKLY       int64\n",
       "AGE              int64\n",
       "AGE2             int64\n",
       "AGE3             int64\n",
       "SEX           category\n",
       "blk           category\n",
       "MARST         category\n",
       "SCHLCOLL      category\n",
       "EDUC          category\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw difference in earnings by race "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association between race and likelihood of annual earnings surpassing 50K (i.e. \"high-income\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.10890816],\n",
       "       [-0.10890816,  1.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(df['50k'], df['blk'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As compared to being white, being black is associatd with a lower likelihood of being high-income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of high-income blacks: 27.9%\n",
      "Percent of high-income whites: 42.76%\n",
      "Difference: 14.86%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percent of high-income blacks: {round(df[df.blk==1]['50k'].mean()*100, 2)}%\")\n",
    "print(f\"Percent of high-income whites: {round(df[df.blk==0]['50k'].mean()*100, 2)}%\")\n",
    "print(f\"Difference: {round((df[df.blk==0]['50k'].mean() - df[df.blk==1]['50k'].mean())*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association between race and log hourly wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.11854933],\n",
       "       [-0.11854933,  1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(df['lnwage'], df['blk'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being black is also correlated with lower hourly wages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean hourly wage, Blacks: $21.34\n",
      "Mean hourly wage, Whites: $26.73\n",
      "Difference: $5.39\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean hourly wage, Blacks: ${round(df[df.blk==1]['hrwage'].mean(), 2)}\")\n",
    "print(f\"Mean hourly wage, Whites: ${round(df[df.blk==0]['hrwage'].mean(), 2)}\")\n",
    "print(f\"Difference: ${round((df[df.blk==0]['hrwage'].mean() - df[df.blk==1]['hrwage'].mean()), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrimination in predicting high/low earners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['50k']\n",
    "X = df[['blk', 'AGE', 'AGE2', 'AGE3', 'SEX', 'EDUC', 'SCHLCOLL', 'MARST', 'pt']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=999)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38642, 9)\n",
      "(9661, 9)\n",
      "(5368, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminatory model: Includes race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = lgb.LGBMClassifier(objective='binary',\n",
    "                           random_state=999,\n",
    "                           metric='logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(metric='logloss', objective='binary', random_state=999)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='logloss', early_stopping_rounds=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7547,\n",
       " 'sensitivity/recall': 0.7206,\n",
       " 'specificity': 0.7773,\n",
       " 'precision': 0.6827,\n",
       " 'f1': 0.7011,\n",
       " 'roc_auc': 0.749}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(y_test, disc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrim = combine_prediction(X_test, disc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance: Blacks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7799,\n",
       " 'sensitivity/recall': 0.5244,\n",
       " 'specificity': 0.874,\n",
       " 'precision': 0.6051,\n",
       " 'f1': 0.5619,\n",
       " 'roc_auc': 0.6992}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Model performance: Blacks\")\n",
    "mask = discrim[discrim.blk==1]\n",
    "metrics(mask['50k'], mask['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance: Whites\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.75,\n",
       " 'sensitivity/recall': 0.7436,\n",
       " 'specificity': 0.7547,\n",
       " 'precision': 0.69,\n",
       " 'f1': 0.7158,\n",
       " 'roc_auc': 0.7492}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Model performance: Whites\")\n",
    "mask = discrim[discrim.blk==0]\n",
    "metrics(mask['50k'], mask['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Blacks predicted to be high-income: 23.33%\n",
      "Percent of Whites predicted to be high-income: 45.63%\n",
      "Difference: 15.43%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percent of Blacks predicted to be high-income: {round(discrim[discrim.blk==1]['pred'].mean()*100, 2)}%\")\n",
    "print(f\"Percent of Whites predicted to be high-income: {round(discrim[discrim.blk==0]['pred'].mean()*100, 2)}%\")\n",
    "print(f\"Difference: {round((discrim[discrim.blk==0]['50k'].mean() - discrim[discrim.blk==1]['50k'].mean())*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive model: Excluding race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = lgb.LGBMClassifier(objective='binary',\n",
    "                           random_state=999,\n",
    "                           metric='logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(metric='logloss', objective='binary', random_state=999)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mod = X_train.loc[:, X_train.columns != 'blk']\n",
    "X_val_mod = X_val.loc[:, X_val.columns != 'blk']\n",
    "X_test_mod = X_test.loc[:, X_test.columns != 'blk']\n",
    "model2.fit(X_train_mod, y_train, eval_set=[(X_val_mod, y_val)], eval_metric='logloss', early_stopping_rounds=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_pred = model2.predict(X_test_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7493,\n",
       " 'sensitivity/recall': 0.6884,\n",
       " 'specificity': 0.7897,\n",
       " 'precision': 0.6852,\n",
       " 'f1': 0.6868,\n",
       " 'roc_auc': 0.7391}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(y_test, naive_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = combine_prediction(X_test, naive_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance: Blacks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7715,\n",
       " 'sensitivity/recall': 0.6756,\n",
       " 'specificity': 0.8069,\n",
       " 'precision': 0.563,\n",
       " 'f1': 0.6142,\n",
       " 'roc_auc': 0.7412}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Model performance: Blacks\")\n",
    "mask = naive[naive.blk==1]\n",
    "metrics(mask['50k'], mask['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance: Whites\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7451,\n",
       " 'sensitivity/recall': 0.6899,\n",
       " 'specificity': 0.7857,\n",
       " 'precision': 0.7028,\n",
       " 'f1': 0.6963,\n",
       " 'roc_auc': 0.7378}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Model performance: Whites\")\n",
    "mask = naive[naive.blk==0]\n",
    "metrics(mask['50k'], mask['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Blacks predicted to be high-income: 32.3%\n",
      "Percent of Whites predicted to be high-income: 41.57%\n",
      "Difference: 15.43%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percent of Blacks predicted to be high-income: {round(naive[naive.blk==1]['pred'].mean()*100, 2)}%\")\n",
    "print(f\"Percent of Whites predicted to be high-income: {round(naive[naive.blk==0]['pred'].mean()*100, 2)}%\")\n",
    "print(f\"Difference: {round((naive[naive.blk==0]['50k'].mean() - naive[naive.blk==1]['50k'].mean())*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blk        -0.074327\n",
      "AGE        -0.014878\n",
      "AGE2        0.000765\n",
      "AGE3       -0.000008\n",
      "SEX        -0.181746\n",
      "MARST      -0.018293\n",
      "pt         -0.261424\n",
      "EDUC        0.007673\n",
      "SCHLCOLL   -0.003221\n",
      "dtype: float64\n",
      "blk        -14.458406\n",
      "AGE        -13.127495\n",
      "AGE2        19.673391\n",
      "AGE3       -19.238039\n",
      "SEX        -49.256033\n",
      "MARST      -19.718031\n",
      "pt         -49.979573\n",
      "EDUC        82.793255\n",
      "SCHLCOLL    -1.780773\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jking\\documents\\pythonvirtualenv\\ml_discrimination\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "y = df['50k']\n",
    "X_reg = df[['blk', 'AGE', 'AGE2', 'AGE3', 'SEX', 'MARST', 'pt', 'EDUC', 'SCHLCOLL']]\n",
    "for x in X_reg.columns:\n",
    "    X_reg[x] = X_reg[x].astype(float)\n",
    "#X_reg = df[['blk', 'AGE', 'AGE2', 'AGE3', 'SEX', 'MARST', 'pt']]\n",
    "results = OLS(y, X_reg,hasconst=False).fit()\n",
    "print(results.params)\n",
    "print(results.tvalues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
