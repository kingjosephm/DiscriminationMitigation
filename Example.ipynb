{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from DiscriminationMitigation import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_synth(n=10000, class_probab=0.5, gamma0=4, gamma1=6, alpha0=2, alpha1=1, beta0=1, beta1=1):\n",
    "\n",
    "    np.random.seed(123)\n",
    "\n",
    "    # Protected class variable\n",
    "    c1 = np.random.binomial(1, p=class_probab, size=n) # group 1\n",
    "    c0 = 1-c1 # group 0\n",
    "\n",
    "    # Other covariate\n",
    "    w = gamma0*c0 + gamma1*c1 + np.random.normal(0, 0.5, size=n) # linear function of class & shock\n",
    "\n",
    "    # Outcome variable\n",
    "    y = alpha0*c0 + alpha1*c1 + beta0*c0*w + beta1*c1*w + np.random.normal(0, 0.5, size=n)\n",
    "\n",
    "    return pd.DataFrame([y, c0, c1, w]).T.rename(columns={0:'y', 1: 'c0', 2: 'c1', 3: 'w'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate some synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          y   c0   c1         w  z  a   b   c\n",
      "0  7.383773  0.0  1.0  6.479200  2  1  10  18\n",
      "1  6.255114  1.0  0.0  4.230080  3  1  11  14\n",
      "2  5.614841  1.0  0.0  3.773609  4  1   4  19\n",
      "3  7.692184  0.0  1.0  6.553467  4  1  13  19\n",
      "4  7.440835  0.0  1.0  6.139432  1  1  12  19\n",
      "\n",
      " (10000, 8)\n"
     ]
    }
   ],
   "source": [
    "synth = simple_synth()\n",
    "synth['z'] = np.random.randint(low=1, high=5, size=len(synth)) # add higher-dimensional protected class\n",
    "synth['a'] = np.random.randint(low=1, high=2, size=len(synth)) # other random, uncorrelated non-protected class features\n",
    "synth['b'] = np.random.randint(low=1, high=15, size=len(synth))\n",
    "synth['c'] = np.random.randint(low=5, high=20, size=len(synth))\n",
    "print(synth.head())\n",
    "print(\"\\n\", synth.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get example configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'protected_class_features': ['c0', 'c1', 'z'], 'target_feature': ['y']}\n",
      "{'c0': {'0': 0.2, '1': 0.8}, 'c1': {'0': 0.8, '1': 0.2}, 'z': {'1': 0.1, '2': 0.2, '3': 0.4, '4': 0.3}}\n"
     ]
    }
   ],
   "source": [
    "with open('example_config.json') as j:\n",
    "    config = json.load(j)\n",
    "\n",
    "with open('example_weights.json') as j:\n",
    "    weights = json.load(j)\n",
    "\n",
    "print(config)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7600, 7)\n",
      "(1900, 7)\n",
      "(500, 7)\n"
     ]
    }
   ],
   "source": [
    "# Train (and val) / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(synth.loc[:, ~synth.columns.isin(config['target_feature'])],\n",
    "                                                    synth[config['target_feature']], random_state=123,\n",
    "                                                    test_size=500)\n",
    "\n",
    "# Train / val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=123, test_size=0.2)\n",
    "\n",
    "for x in X_train, X_val, X_test:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Keras Sequential deep learning model example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 64        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 225\n",
      "Trainable params: 225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=7,))\n",
    "model.add(tf.keras.layers.Dense(8))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(16))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.2083 - val_loss: 2.1185\n",
      "Epoch 2/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6.5999 - val_loss: 1.4081\n",
      "Epoch 3/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9468 - val_loss: 1.0804\n",
      "Epoch 4/30\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.0355 - val_loss: 0.7382\n",
      "Epoch 5/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 3.1551 - val_loss: 0.6188\n",
      "Epoch 6/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 2.7064 - val_loss: 0.4500\n",
      "Epoch 7/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 2.3662 - val_loss: 0.4490\n",
      "Epoch 8/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 2.0986 - val_loss: 0.3583\n",
      "Epoch 9/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 1.8708 - val_loss: 0.3740\n",
      "Epoch 10/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 1.6239 - val_loss: 0.3588\n",
      "Epoch 11/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 1.4693 - val_loss: 0.3492\n",
      "Epoch 12/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 1.3064 - val_loss: 0.3554\n",
      "Epoch 13/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 1.1887 - val_loss: 0.3517\n",
      "Epoch 14/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 1.0472 - val_loss: 0.3547\n",
      "Epoch 15/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.9606 - val_loss: 0.3497\n",
      "Epoch 16/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.8742 - val_loss: 0.3534\n",
      "Epoch 17/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.8208 - val_loss: 0.3635\n",
      "Epoch 18/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.7603 - val_loss: 0.3631\n",
      "Epoch 19/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.7162 - val_loss: 0.3642\n",
      "Epoch 20/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.7101 - val_loss: 0.3640\n",
      "Epoch 21/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.6921 - val_loss: 0.3709\n",
      "Epoch 22/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.6748 - val_loss: 0.3591\n",
      "Epoch 23/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.6553 - val_loss: 0.3541\n",
      "Epoch 24/30\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 0.6573 - val_loss: 0.3507\n",
      "Epoch 25/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.6309 - val_loss: 0.3451\n",
      "Epoch 26/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.3431\n",
      "Epoch 27/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.6010 - val_loss: 0.3282\n",
      "Epoch 28/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.5664 - val_loss: 0.3258\n",
      "Epoch 29/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.5827 - val_loss: 0.3211\n",
      "Epoch 30/30\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.5549 - val_loss: 0.3043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f4de118fc8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrimination mitigation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jking\\Documents\\ML Discrimination\\scripts\\DiscriminationMitigation.py:135: UserWarning: \n",
      " Warning! The following features are extremely correlated and thus may be one-hot vectors: c0 c1. \n",
      "If no category is omitted, users must ensure custom marginal weights for one-hot vectors align correctly.\n",
      "  \"If no category is omitted, users must ensure custom marginal weights for one-hot vectors align correctly.\".format(' '.join(extreme_corr)))\n"
     ]
    }
   ],
   "source": [
    "pred = DiscriminationMitigator(df=X_test, model=model, config=config, train=X_train, weights=weights).predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe of predictions \n",
      "       unadj_pred  unif_wts   pop_wts  cust_wts\n",
      "2656    7.018159  7.017337  7.033709  7.049608\n",
      "445     6.378776  6.429476  6.428673  6.444573\n",
      "9505    6.237130  6.186430  6.186176  6.202075\n",
      "332     6.783767  6.817292  6.822215  6.838114\n",
      "4168    7.006484  7.005661  7.022033  7.037933\n",
      "\n",
      "Correlation matrix between predictions \n",
      "             unadj_pred  unif_wts   pop_wts  cust_wts\n",
      "unadj_pred    1.000000  0.999065  0.999168  0.999168\n",
      "unif_wts      0.999065  1.000000  0.999914  0.999914\n",
      "pop_wts       0.999168  0.999914  1.000000  1.000000\n",
      "cust_wts      0.999168  0.999914  1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe of predictions \\n\", pred.head())\n",
    "print(\"\\nCorrelation matrix between predictions \\n\", pred.corr())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
